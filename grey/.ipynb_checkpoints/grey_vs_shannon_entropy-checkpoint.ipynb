{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Grey entropy and its application in weighting analysis,         Wen (1998) ](https://ieeexplore.ieee.org/abstract/document/728163)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During past research in weighting analysis, the con-\n",
    "tinuous type of entropy is discussed frequently. How-\n",
    "ever, in the practical system, there are all discrete,\n",
    "if we use the continuous type of entropy to solve our\n",
    "problems, although problems were solved, there still\n",
    "exists some vagueness in our minds. Therefore, in this\n",
    "paper, we try to let the vagueness disappear. So, we\n",
    "based on the definition of entropy to derive the dis-\n",
    "crete type of entropy, and it calls __grey entropy__. After\n",
    "the grey entropy is derived, we also give an example\n",
    "to compare the traditional entropy and the grey en-\n",
    "tropy. As a results, we can find the grey entropy is\n",
    "one of the suitable method in weighting analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a new entropy under conditions based on Shannon entropy:\n",
    "1. $f_i ( 0 ) = 0 $\n",
    "2. $f_i ( x ) = f_i ( 1-x )$\n",
    "3. $f_i(x)$ is monotonic increasing in the $x \\in  (0,0.5)$.\n",
    "\n",
    "__Definition 1:__ For the function of $x$ the entropy function is defined as:\n",
    "$$W(A) = \\frac{\\sum^m_{i=1} W_e(X_i)}{(e^{1/2}-1)m}$$\n",
    "where $W_e(x) = xe^{(1-x)}+(1-x)e^x-1$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the mentioned above, we already developed a new\n",
    "continuous type, but in the practical world, there all\n",
    "are discrete. Therefore, we imply the concept “least\n",
    "information theory” of grey system theory to create the grey entropy for our need. \n",
    "\n",
    "Grey entropy is one of\n",
    "the suitable method for the weighting analyze in our\n",
    "practical world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Shannon Entropy](http://bearcave.com/misl/misl_tech/wavelets/compression/shannon.html)\n",
    "\n",
    "https://en.wiktionary.org/wiki/Shannon_entropy\n",
    "\n",
    "https://en.wikipedia.org/wiki/Entropy_(information_theory)\n",
    "\n",
    "https://arxiv.org/pdf/1405.2061.pdf\n",
    "\n",
    "http://www.ueltschi.org/teaching/chapShannon.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [The intuition behind Shannon’s Entropy]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deﬁne the self-information of an event $X = x$ to be\n",
    "$I(x) = −\\log P (x)$\n",
    "Our definition of $I(x)$ is therefore written in units of nats. One nat is the amount of information gained by observing an event of probability $1/e$.\n",
    "\n",
    "$$H(x)=-\\sum_xP(x)\\log{P(x)}= \\sum_x P(x)\\log(\\frac{1}{P(x)})$$\n",
    "\n",
    "$H(X)$ is the total amount of information in an entire probability distribution. This means $1/p(x)$ should be the information of each case (the unlikely event has a higher entropy).\n",
    "\n",
    "If $b$ is the base of the logarithm used, corresponding units of entropy are the bits for $b = 2$, nats for $b = e$, and bans for $b = 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import random\n",
    "\n",
    "def H(sentence): \n",
    "    \"\"\"\n",
    "    Equation 3.49 (Shannon's Entropy) is implemented.\n",
    "    \"\"\"\n",
    "    entropy = 0 \n",
    "    # There are 256 possible ASCII characters\n",
    "    for character_i in range(256): \n",
    "        Px = sentence.count(chr(character_i))/len(sentence) \n",
    "        if Px > 0: \n",
    "            entropy += - Px * math.log(Px, 2) \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.041086039235804"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The telegrapher creates the \"encoded message\" with length 10000.\n",
    "# When he uses only 32 chars \n",
    "simple_message =\"\".join([chr(random.randint(0,32)) for i in range(10000)])\n",
    "H(simple_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.982323353868584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When he uses all 255 chars, the entropy increases as the uncertainty of which character will be sent increases.\n",
    "complex_message =\"\".join([chr(random.randint(0,255)) for i in range(10000)])\n",
    "H(complex_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
