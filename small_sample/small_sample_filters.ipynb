{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Adaptive filters](http://www.numdam.org/article/RO_1973__7_1_31_0.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Packages\n",
    "\n",
    "- `KFAS`: [Kalman Filter and Smoother for Exponential Family State Space Models](https://cran.r-project.org/web/packages/KFAS/index.html). \n",
    "State space modelling is an efficient and flexible framework for statistical inference of a broad class of time series and other data. KFAS includes computationally efficient functions for Kalman filtering, smoothing, forecasting, and simulation of multivariate exponential family state space models, with observations from Gaussian, Poisson, binomial, negative binomial, and gamma distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Моделирование в пространстве состояний](http://quantile.ru/09/09-AT.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Interpolation based on stationary and adaptive AR(1) modeling](http://publications.lib.chalmers.se/records/fulltext/146866/local_146866.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper, we describe a minimal mean square error (MMSE)\n",
    "optimal interpolation filter for discrete random signals. We explicitly\n",
    "derive the interpolation filter for a first-order autoregressive process\n",
    "(AR(1)), and show that the filter depends only on the two adjacent\n",
    "points. The result is extended by developing an algorithm called\n",
    "local AR approximation (LARA), where a random signal is locally\n",
    "estimated as an AR(1) process. Experimental evaluation illustrates\n",
    "that LARA interpolation yields a lower mean square error than other\n",
    "common interpolation techniques, including linear, spline and local\n",
    "polynomial approximation (LPA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a discrete random signal with known spectrum, we derive\n",
    "the optimal interpolation filter in a minimum mean square error\n",
    "(MMSE) sense.   We derive an\n",
    "explicit form of this filter for a stationary first-order autoregressive\n",
    "process (AR(1)).  The resulting filter is then extended to a general\n",
    "interpolation algorithm, that can be used on a larger set of signals. This is done by approximating the signal locally as an AR(1) process, where the AR(1) parameter is estimated from the data without\n",
    "prior information about the original signal. We name this algorithm\n",
    "local AR approximation (LARA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of LARA interpolation, we compare it with other interpolation techniques: linear, spline and local\n",
    "polynomial approximation (LPA)  interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us therefore introduce the filters $H_k, (k = 0, .., L − 1)$,\n",
    "where $H_k$ reconstructs samples of the form\n",
    "$$x_{dk}[n] = x[nL + k]$$\n",
    "For each of these interpolation filters, the optimal filter, in the MMSE sense, is a Wiener filter:\n",
    "$$ H_k(e^{jΩ_d} ) = \\frac{P_{x_dx_{dk}} (e^{jΩd} )}{P_{x_dx_d} (e^{jΩd} ) }$$\n",
    "where $Ω_d$ is the angular frequency in radians/sample, $P_{x_dx_d}$ is the\n",
    "spectrum of $x_d$ and $P_{x_dx_{dk}}$ is the cross spectrum of $x_d$ and $x_{dk}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application to a first-order autoregressive process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that the process $x[n]$ is a stationary AR(1) process,\n",
    "$$x[n] = ax[n − 1] + v[n]$$\n",
    "\n",
    "Since the AR(1) process is Markovian, it is reasonable that the\n",
    "optimal interpolation filter only needs to consider information from\n",
    "the two adjacent points. While downsampled AR(1) processes are\n",
    "still AR(1), this is unfortunately not the case for higher-order AR\n",
    "processes, thereby limiting the generalisation of Proposition about MMSE optimal interpolation filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison to linear interpolation\n",
    "\n",
    "The filter produces interpolation points by a\n",
    "weighted mean of the previous and the following sample point.\n",
    "Note the close relationship between the AR(1) filter and ordinary\n",
    "linear interpolation, defined as\n",
    "$$x[Ln + k] = \\frac{(L − k)}{L}  x_d[n] + \\frac{k}{L}x_d[n + 1]$$\n",
    "and for the AR(1) interpolation filter.\n",
    "\n",
    "Fig.1 shows that the coefficients of the AR(1) filter are damped versions of the linear interpolation coefficients. The AR(1) filter considers the stochastic nature of the signal and introduces a bias towards the mean, which in this case is zero. The larger $a$ is (i.e., less\n",
    "stochasticity), the more our filter resembles linear interpolation.\n",
    "\n",
    "Local AR approximation (LARA) can be seen\n",
    "as a stochastic version of the LPA method, the latter being better\n",
    "suited for deterministic signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Wiener filter](https://en.wikipedia.org/wiki/Wiener_filter)\n",
    "\n",
    "In signal processing, the Wiener filter is a filter used to produce an estimate of a desired or target random process by linear time-invariant (LTI) filtering of an observed noisy process, assuming known stationary signal and noise spectra, and additive noise. The Wiener filter minimizes the mean square error between the estimated random process and the desired process.\n",
    "\n",
    "The goal of the Wiener filter is to compute a statistical estimate of an unknown signal using a related signal as an input and filtering that known signal to produce the estimate as an output. For example, the known signal might consist of an unknown signal of interest that has been corrupted by additive noise. The Wiener filter can be used to filter out the noise from the corrupted signal to provide an estimate of the underlying signal of interest. The Wiener filter is based on a statistical approach, and a more statistical account of the theory is given in the minimum mean square error (MMSE) estimator article.\n",
    "\n",
    "Wiener filters are characterized by the following:\n",
    "\n",
    "- Assumption: signal and (additive) noise are stationary linear stochastic processes with known spectral characteristics or known autocorrelation and cross-correlation\n",
    "- Requirement: the filter must be physically realizable/causal (this requirement can be dropped, resulting in a non-causal solution)\n",
    "- Performance criterion: minimum mean-square error (MMSE)\n",
    "\n",
    "This filter is frequently used in the process of deconvolution; for this application, see Wiener deconvolution:\n",
    "\n",
    "Given a system:\n",
    " $$y(t)=(h* x)(t)+n(t)$$\n",
    "where $x(t)$  is some original signal (unknown) at time  $t$, \n",
    "$ h(t)$  is the known impulse response of a linear time-invariant system, $n(t)$  is some unknown additive noise, $y(t)$ is our observed signal\n",
    "\n",
    "Our goal is to find some  $g(t)$ so that we can estimate  $x(t)$ as follows:\n",
    "$$ \\hat{x}(t)=(g∗y)(t)$$ \n",
    "where  ${\\hat {x}}(t)$ is an estimate of  $ x(t)$  that minimizes the mean square error.\n",
    "\n",
    "The Wiener deconvolution filter provides such a  $g(t)$. The filter is most easily described in the frequency domain:\n",
    "\n",
    "$$G(f)={\\frac {H^{*}(f)S(f)}{|H(f)|^{2}S(f)+N(f)}}$$\n",
    "where $G(f)$ and  $H(f)$ are the Fourier transforms of  $g$  and  $h$, respectively at frequency  $f$; $ S(f)$ is the mean power spectral density of the original signal  $x(t)$;  $N(f)$ is the mean power spectral density of the noise  $n(t)$ \n",
    "\n",
    "The filtering operation may either be carried out in the time-domain, as above, or in the frequency domain:\n",
    "\n",
    " $${\\hat {X}}(f)=G(f)Y(f)$$\n",
    "\n",
    "where ${\\displaystyle {\\hat {X}}(f)}$ and ${\\displaystyle Y(f)}$ are the Fourier transforms of ${\\hat {x}}(t)$ and $y(t)$; then  inverse Fourier transform is performed on   ${\\hat {X}}(f)$ to obtain  ${\\hat {x}}(t)$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Bayesian estimation, also known as a Bayes filter, is a general probabilistic approach for estimating an unknown probability density function recursively over time using incoming measurements and a mathematical process model.\n",
    "\n",
    "If the variables are normally distributed and the transitions are linear, the Bayes filter becomes equal to the Kalman filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Introduction to recursive Bayesian filtering](https://people.csail.mit.edu/mrub/talks/filtering.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Noisy measurements\n",
    "Goal: Estimate most probable measurement at time $k$ using\n",
    "measurements up to time $k'$\n",
    "- $k'<k$: prediction, when estimating a probable future value given the present and the past measures\n",
    "- $k'>k$: smoothing, when estimating past values given present and past measures, \n",
    "- $k'=k$: filtering,  when estimating the current value given past and current observations\n",
    "\n",
    "\n",
    "\n",
    "__(First‐order) Markov process:__\n",
    "\n",
    "The Markov property - the likelihood of a future state depends on present state only:\n",
    "\n",
    "$$ Pr[X (k+h ) =y| X(s) =x(s), \\forall s \\leq k ] = Pr[X (k+h ) =y| X(k) =x(k)],  \\forall h >  0 $$\n",
    "\n",
    "\n",
    "Markov chain – a stochastic process with\n",
    "Markov property\n",
    "\n",
    "Hidden Markov Model (HMM) - the state is not directly visible, but output dependent on the state is visible\n",
    "\n",
    "__State space:__\n",
    "- The state vector contains all available information information to describe describe the investigated investigated system (usually multidimensional)\n",
    "- The measurement vector represents observations related to the state vector (generally, but not necessarily, of lower dimension than the state vector)\n",
    "\n",
    "__Dynamic System__\n",
    "\n",
    "State equation: $ x_k = f_k ( x_{k-1}, v_k) $\n",
    "\n",
    "Observation equation: $ z_k = h_k ( x_{k}, w_k) $\n",
    "\n",
    "- $x_k $ - state vector at time instant  $k$, $z_k$ observations at time instant  $k$; \n",
    "\n",
    "- $f_k: R^{N_x} \\times R^{N_v} \\to R^{N_x}$ - state transition function, \n",
    "- $h_k: R^{N_x} \\times R^{N_w} \\to R^{N_z}$ - observation function;\n",
    "\n",
    "- $v_k$ - i.i.d process noise, $w_k$ - i.i.d measurement noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Bayes filters\n",
    "Given:\n",
    "- System models in probabilistic forms (known statistics of $v_k, w_k$):\n",
    "$$x_k = f_k(x_{k-1}, v_k )  \\leftrightarrow  p(x_k |x_{k-1} ) \\\\\n",
    "z_k = h_k(x_{k}, w_k )  \\leftrightarrow  p(z_k |x_{k} )$$\n",
    "- Initial state $p(x_0|z_0 ) = p(x_0)$ also known as the prior\n",
    "- Measurements $z_1,\\dots, z_k$\n",
    "\n",
    "Prediction step (a‐priori):\n",
    "$$p(x_{k-1}| z_{1:k-1}) \\to p(x_k| z_{1:k-1})$$\n",
    "- Uses the system model to predict forward\n",
    "- Deforms/translates/spreads state pdf due to random noise\n",
    "\n",
    "Update step (a‐posteriori):\n",
    "$$p(x_k|z_{1:k-1} ) \\to p(x_k |z_{1:k}) $$ \n",
    "- Update the prediction in light of new data\n",
    "- Tightens the state pdf\n",
    "\n",
    "Prediction:\n",
    "$$p(x_k|z_{1:k-1} ) = \\int  p(x_k |x_{k-1})  p(x_{k-1} |z_{1:k-1})dx_{k-1} $$ \n",
    "- $p(x_k |x_{k-1})$ - system model\n",
    "- $p(x_{k-1} |z_{1:k-1})$ - previous posterior \n",
    "- Using Chapman‐Kolmogorov identity + Markov property\n",
    "\n",
    "Update step:\n",
    "$$p(A|B,C) = \\frac{p(B|A,C) p(A|C)}{p(B|C)} \\\\ \n",
    "p(x_k|z_{1:k} ) =  p(x_k |z_k, z_{1:k-1}) =  \\frac{p(z_{k}|x_k) p(x_{k}|z_{1:k-1})}{p(z_k|z_{1:k-1})}   $$\n",
    "- $p(z_{k}|x_k)$ - Likelihood - measurement model\n",
    "- $p(x_{k}|z_{1:k-1})$ - Prior - current prior\n",
    "- $p(z_k|z_{1:k-1})$  - Measurement - normalization  constant\n",
    "\n",
    "\n",
    "Generating estimates:\n",
    "- Knowledge of $p(x_k|z_{1:k})$ enables to compute optimal estimate with respect to any criterion. \n",
    "    - Minimum mean‐square error (MMSE): $\\hat{x}_{k| k}^{MMSE}= E[ x_k| z_{1:k}] = \\int  x_k p( x_k |z_{1:k}) dx_k $\n",
    "    - Maximum a‐posteriori: $\\hat{x}^{MAP}_{k|k} = \\arg \\max_{x_k} p (x_k | z_k) $\n",
    "    "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [From Bayes to Extended Kalman Filter](http://people.ciirc.cvut.cz/~hlavac/TeachPresEn/55AutonomRobotics/2015-05-04ReinsteinBayes-ekf.pdf)\n",
    "\n",
    "Overview of the Probability Rules:\n",
    "- $A, B$ are conditionally independent: $P(A, B|C) = P(A|C)P(B|C)$\n",
    "- The Bayes theorem: $ P(A|B) = \\frac{P (B|A)P (A)}{\\sum_A P (B|A) P (A)} $\n",
    "- General inference: $ P(V |S) = \\frac{P(V, S)}{P(S)} = \\frac{\\sum_{A,B,C} P(S, A, B, C, V ) }{\\sum_{S,A,B,C} P(S, A, B, C, V )}$\n",
    "\n",
    "Multivariate Normal distribution: \n",
    "- $p(x;\\mu,\\Sigma) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}} \\exp{(-1/2 (x-\\mu)^T \\Sigma^{-1}(x-\\mu))}$\n",
    "- $\\mu = 1/m \\sum_{i=1}^m  x^{(i)}$\n",
    "- $\\Sigma = 1/m \\sum^m_{i=1} (x^{(i)}-\\mu) (x^{(i)}-\\mu)^T$\n",
    "\n",
    "MAP - Maximum A-Posteriori Estimation:\n",
    "\n",
    "Given an observation $z$, a likelihood function $p(z|x)$ and prior distribution\n",
    "$p(x)$ on $x$, the maximum a posteriori estimator MAP finds the value of $x$\n",
    "which maximizes the posterior distribution $p(x|z)$:\n",
    "$$\\hat{x}_{MAP} = \\arg \\max_x p(z|x)p(x)$$\n",
    "\n",
    "\n",
    "MMSE - Minimum Mean Squared Error:\n",
    "\n",
    "We want to find such a $\\hat{x}$, an estimate of $x$, that given a set\n",
    "of measurements $Z^k = \\{z_1,\\dots, z_k\\}$ it minimizes the mean squared error between the true value and this estimate.\n",
    "$$\\hat{x}_{MMSE} = \\arg \\min_{\\hat{x}} E\\{ (\\hat{x} − x)^T (\\hat{x} − x) | Z^k\\} = E\\{x|Z^k\\}$$\n",
    "The MMSE estimate given a set of measurements is\n",
    "the mean of that variable conditioned on the measurements! \n",
    "\n",
    "__RBE - Recursive Bayesian Estimation__\n",
    "\n",
    "RBE is the natural extension of MAP to time-stamped sequence of observations\n",
    "being processed at each time step. In RBE we use the priory estimate and current measurement to compute the posteriori estimate $\\hat{x}$.\n",
    "- When the next measurement comes we use our previous posteriori estimate as a new prior and proceed with the same estimation rule.\n",
    "- Hence for each time-step $k$ we obtain an estimate for it’s state given all observations up to that time (the set Z\n",
    "- Using the Bayes rule and conditional independence of measurements:\n",
    "$$p(x, Z^k) = p(x|Z^k)p(Z^k) = p(Z^k|x)p(x) = p(Z^{k−1}|x)p(z_k|x)p(x)$$\n",
    "- We express $p(Z^{k−1}|x)$ and substitute for it to get:\n",
    "$$p(x|Z^k) = \\frac{p(z_k|x)p(x|Z^{k−1})p(Z^{k−1})}{p(Z^k)}$$\n",
    "\n",
    "RBE is extension of MAP to time-stamped sequence of observations: we obtain RBE as the likelihood of current $k^{th}$ measurement\n",
    "times prior which is our last best estimate of $x$ at time $k − 1$ conditioned on\n",
    "measurement at time $k − 1$ (denominator is just a normalizing constant):\n",
    "\n",
    "$$p(x|Z^k) = \\frac{p(z_k|x)p(x|Z^{k−1})}{p(z^k|Z^{k-1})}=\\frac{current \\  likelihood \\times last \\ best \\ estimate}{normalizing \\ constant\n",
    "}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applications: \n",
    "\n",
    "- Kalman filter, a recursive Bayesian filter for multivariate normal distributions\n",
    "- Particle filter, a sequential Monte Carlo (SMC) based technique, which models the PDF using a set of discrete points \n",
    "- Grid-based estimators, which subdivide the PDF into a deterministic discrete grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Kalman filter](https://jyx.jyu.fi/bitstream/handle/123456789/49043/ThesisJouniHelske.pdf?sequence=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear Gaussian state space model can be written as\n",
    "$$y_t = Z_tα_t + e_t, \\ (observation  \\ equation) \\\\ \n",
    "α_{t+1} = T_tα_t + R_tη_t \\  (state \\  equation) $$\n",
    "where $e_t \\sim N(0, H_t), η_t \\sim N(0, Q_t),  α_1 \\sim N(a_1, P_1)$ independently of each other. Here\n",
    "the vector $y_t$ contains the observations at time $t$, whereas $α_t$\n",
    "is the vector of the latent state\n",
    "process at time $t$. The system matrices $Z_t, T_t, R_t$, together with the covariance matrices $H_t$ and $Q_t$ depend on the particular model definition, and often some of these matrices contain\n",
    "unknown (hyper)parameters $ψ$ which need to be estimated. If a particular matrix such as $Z_t$ does not depend on $t$, it is said to be time-invariant. \n",
    "\n",
    "The main algorithms for the inference of Gaussian state space models are the Kalman filtering\n",
    "and smoothing recursions. From the Kalman filtering algorithm we obtain the one-step-ahead predictions and the prediction errors\n",
    "$$ a_{t+1} = E(α_{t+1}|y_t, ... , y_1)\\\\ v_t = y_t − E(y_t|y_{t−1}, ... , y_1)$$\n",
    "and their covariance matrices:\n",
    "$$P_{t+1} = Var(α_{t+1}|y_t, ... , y_1) \\\\ F_t = Var(v_t)$$\n",
    "\n",
    "$a_{t+1}$ is also the minimum variance linear posterior mean\n",
    "estimate. Therefore, given the hyperparameters $ψ$, the resulting predictive distributions are Bayesian posterior distributions given the prior distribution $N(a_1, P_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State space models can also be extended to non-Gaussian cases. In\n",
    "the R package KFAS presented in Article IV, possible choices for observational distributions\n",
    "are Gaussian, Poisson, binomial, negative binomial and gamma distributions. Note that it is\n",
    "possible to define a multivariate model where each series has different distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [The Kalman filter](https://people.csail.mit.edu/mrub/talks/filtering.pdf)\n",
    "\n",
    "$$p( x_{k-1}| z_{1:k-1} =  N (x_{k-1}; \\hat{x}_{k-1|k-1},  P_{k-1|k-1}) \\\\ p( x_{k}| z_{1:k-1} =  N (x_{k}; \\hat{x}_{k|k-1},  P_{k|k-1} )\\\\\n",
    "p( x_{k}| z_{1:k} =  N (x_{k}; \\hat{x}_{k|k},  P_{k|k})$$\n",
    "\n",
    "Substituting yields the predict and update equations\n",
    "\n",
    "Predict:\n",
    "$$\\hat{x}_{k|k-1}=F_k\\hat{x}_{k-1|k-1} \\\\\n",
    "P_{k|k-1} = F_kP_{k-1|k-1}F_k^T + Q_k$$\n",
    "\n",
    "Update:\n",
    "$$S_k=H_kP_{k|k-1}H^T_k +R_k\\\\\n",
    "K_k=P_{k|k-1}H^T_kS^{-1}_k \\\\\n",
    "\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k (z_k - H_k \\hat{x}_{k|k-1}) \\\\\n",
    "P_{k|k} = [I-K_kH_k]P_{k|k=1}\n",
    "$$\n",
    "where $S_k$ - innovation (or pre-fit residual) covariance, $K_k$ - optimal Kalman gain, $ \\hat{x}_{k|k} $ - updated (a posteriori) state estimate, $P_{k|k}$ - updated (a posteriori) estimate covariance\n",
    "\n",
    "Pros: \n",
    "- Optimal Optimal closed‐form solution solution to the tracking tracking problem problem (under the assumptions): no algorithm can do better in a linear‐Gaussian environment\n",
    "- All ‘logical’ estimations collapse to a unique solution \n",
    "- Simple to implement and fast to execute\n",
    "\n",
    "Cons:\n",
    "- If either the system or measurement model is non‐ linear, then the posterior will be non‐Gaussian\n",
    "\n",
    "#### The extended Kalman filter\n",
    "\n",
    "The idea: local linearization of the dynamic\n",
    "system might be sufficient description of the\n",
    "nonlinearity\n",
    "\n",
    "The model: nonlinear system with additive\n",
    "noise\n",
    "\n",
    "Pros:\n",
    "- Good approximation approximation when models are near‐linear\n",
    "- Efficient to calculate\n",
    "\n",
    "Cons:\n",
    "- Only approximation (optimality not proven)\n",
    "- Still a single Gaussian approximations\n",
    "- If we have multimodal hypothesis, and choose incorrectly – can be difficult to recover\n",
    "- Inapplicable when $f,h$ discontinuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [A Recursive Kalman Filter Forecasting Approach](https://www.researchgate.net/publication/227445310_A_Recursive_Kalman_Filter_Forecasting_Approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper examines the forecasting accuracy and the cost effectiveness of time series models with time-varying coefficients. A simulation study investigates the potential forecasting\n",
    "benefits of a proposed Kalman filter type adaptive estimation and forecasting approach. \n",
    "- When appropriate, the time-varying coefficient approach leads to better forecasts than the constant coefficient procedures.\n",
    "- A simple decision rule, which indicates whether time-varying coefficient models are in fact needed, increases the computational efficiency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasters are frequently concerned that the coefficients in their forecast models \n",
    "are not constant, but change over time. This concern has led to the development of\n",
    "various adaptive forecast procedures. For example, adaptive exponential smoothing\n",
    "methods are designed to improve the forecast performance by\n",
    "letting the smoothing constant vary according to the most recent forecast accuracy.\n",
    "As new observations become available, the\n",
    "parameter estimates and forecasts are revised by heuristic recursive algorithms.\n",
    "Adaptive filtering is one such\n",
    "heuristic adaptive technique. \n",
    "\n",
    "There the estimate of the coefficient vector \n",
    "$ \\beta $ in the autoregressive prediction model $z_t = \\sum_{i=1}^p \\beta_i z_{t-i} +e_t $\n",
    "is updated according to $\\hat{\\beta}_t= \\hat{\\beta}_{t-1} + 2 \\alpha e_t^* z^*_{(i)}$. The constant $ \\alpha$ is a learning coefficient,\n",
    "$e^*_t$: is the standardized one step ahead forecast error, and $z^*_{(t)}$ is a vector of standardized observations. \n",
    "\n",
    "Adaptive filtering is a heuristic method and\n",
    "makes no reference to a probabilistic model which describes the changes in the\n",
    "coefficients. The ad hoc chosen learning constant determines how fast past observations are discounted. Due to its heuristic nature this technique has been criticized for\n",
    "its lack of a sound theoretical basis.\n",
    "\n",
    "__Estimation:__\n",
    "\n",
    "To update the coefficients and the forecasts one has to specify values for $T$ and $\\Omega$.\n",
    "Different values for $T$ and $\\Omega$ will lead to different Kalman gain vectors, and thus to\n",
    "different updating weights. \n",
    "\n",
    "Here, however, we do not restrict ourselves to constant coefficients a priori, but estimate $T$ and $\\Omega$ from past data, using a maximum likelihood estimation\n",
    "approach. \n",
    "\n",
    "The recursive equations depend on the initial values $\\hat{\\beta}_{0|0}$ and $P_{0|0}$. The\n",
    "traditional approach for picking these values is to choose a large diagonal matrix for $P_{0|0}$. It measures the uncertainty associated with $\\beta_0$, before observations have become\n",
    "available, and diminishes the influence of the initial $\\hat{\\beta}_{0|0}$ which is usually set zero.\n",
    "\n",
    "\n",
    "__The results:__ \n",
    "- If the coefficients are in fact constant, then the recursive Kalman filter forecasting approach actually leads to small increases in the forecast errors. \n",
    "- If the coefficients are timevarying, then the recursive Kalman filter forecast approach does lead to forecast improvements, especially for short lead times. Our results show that the presence of stochastic time-varying coefficients can be detected and be used to derive improved forecasts.\n",
    "\n",
    "The first conclusion is consistent with the results of Gardner and Dannenbring\n",
    "who find that adaptive forecast methods increase the forecast errors if the coefficients\n",
    "are in fact constant.  Such increase can be explained by the fact that the estimation of\n",
    "an additional parameter  introduces additional\n",
    "uncertainty.\n",
    "\n",
    "\n",
    "Gardner and Dannenbring also compare the forecast performance of constant and\n",
    "adaptive exponential smoothing methods, when the level and/or the slope in the linear\n",
    "trend model, are subject to step changes. They find that in general\n",
    "adaptive exponential smoothing procedures do not produce more accurate forecasts than the fixed parameter methods. \n",
    "Also, the particular choice of the smoothing constant in the Gardner and Dannenbring study may have biased the results in\n",
    "favor of the constant coefficient methods\n",
    "\n",
    "\n",
    "The empirical results of this paper indicate that in cases, in which time-varying\n",
    "coefficients are expected, the recursive Kalman filter forecasting approach will lead to\n",
    "smaller forecast errors. \n",
    "The simulations show the usefulness of the\n",
    "likelihood ratio test criterion for detecting such changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### [Other filters](https://people.csail.mit.edu/mrub/talks/filtering.pdf)\n",
    "\n",
    "- [Filters for Short Nonstationary Sequences: The Analysis of the Business Cycle](https://www.le.ac.uk/users/dsgp1/SIGNALS/BRITPORT.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Grid‐based filter\n",
    "\n",
    "The posterior pdf at $k‐1$ can be expressed as\n",
    "sum of delta function\n",
    "\n",
    "Pros:\n",
    "- $p(x_k |x_{k-1} ), p(z_k |x_k )$ assumed known, but no\n",
    "constraint on their (discrete) shapes\n",
    "- Easy extension to varying number of states\n",
    "- Optimal solution for the discrete‐finite environment!\n",
    "\n",
    "Cons:\n",
    "- Curse of dimensionality (inefficient if the state space is large)\n",
    "- Statically considers all possible hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Particle filtering\n",
    "\n",
    "General concept: represent the posterior pdf by a set of randomly chosen weighted samples (particles)\n",
    "\n",
    "- Randomly Chosen: Monte Carlo (MC)\n",
    "- As the number of samples become very large, the characterization becomes an equivalent representation of the true pdf\n",
    "\n",
    "Pros:\n",
    "- Can represent any arbitrary distribution (multimodal support)\n",
    "- Keep track several hypotheses simultaneously\n",
    "- Approximate representation of complex model rather than exact representation of simplified model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavelet filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Time series forecasting based on wavelet filtering](https://www.researchgate.net/publication/272239872_Time_series_forecasting_based_on_wavelet_filtering):  Through wavelet transforms, the series is partitioned into two parts (trends and variations). We then construct a separate model for each part. By this partitioning, the proposed method is especially useful for the time series with a large amount of noise. The potential overfitting problem of this approach caused by using two separate models is addressed by adjusting the decomposition levels.\n",
    "- [Combining wavelet and Kalman filters for financial time series forecasting](https://pdfs.semanticscholar.org/02b5/4c41a815689d787a483796c04a55beedf64b.pdf): what would happen if the filtering techniques were combined? That is, if the Kalman filter was used and the wavelets were then used in its filter to make the forecasting with recurrent neural networks, since the networks improve the non-linear adjustment of the data or whether the reverse would bring better results. \n",
    "- Off-top: [Macroeconomic forecasting using low-frequency filters](https://www.bportugal.pt/sites/default/files/anexos/papers/wp201301.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
