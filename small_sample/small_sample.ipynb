{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the minimum number of observations required to perform a statistically significant panel analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, Ferron et al. (2009) showed that a Kenward-Roger correction can provide appropriate standard errors well into the single digits for a fairly simple model and Browne and Draper (2006) were able to obtain unbiased variance components with REML estimation with only 6 units at the highest level (again for a simple model). Gelman (2006) showed that Bayesian methods can produce unbiased estimates of variance components with as few as 3 units at the highest level using a carefully considered, weakly informative prior. If you are worried that 11 is not enough at the highest level, keeping the model as simple as possible is the best way to guard against possible small sample bias (beside collecting more data which is usually not a reasonable suggestion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the sufficient sample size in multilevel analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I don't know of any small sample studies that have gone beyond two-levels. In two-level models, without using any small sample correction (e.g., Kenward-Roger), with continuous outcomes, about 20 units are needed at the highest level to obtain unbiased estimates (power will be quite low though). With discrete outcomes, about 50 units are needed at the highest level with at least 5 observations per cluster. \n",
    "\n",
    "A relevant paper might be McNeish & Stapleton (2014, Educational Psychology Review) which is a review paper and contains several references that may be helpful for the specifics of your situation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best method for short time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the robustness of different methods to these simple ones, e.g., by not only assessing average accuracy out-of-sample, but also the error variance, using your favorite error measure.\n",
    "\n",
    "The first approach is to use standard/linear time series models (AR, MA, ARMA, etc.), but to pay attention to certain parameters, as described in this post [1] by Rob Hyndman, who does not need an introduction in time series and forecasting world. The second approach, referred to by most of the related literature that I have seen, suggest using non-linear time series models, in particular, the threshold models [2], which include threshold autoregressive model (TAR), self-exiting TAR (SETAR), threshold autoregressive moving average model (TARMA), and TARMAX model, which extends TAR model to exogenous time series. Excellent overviews of the non-linear time series models, including threshold models, can be found in this paper [3] and this paper [4].\n",
    "\n",
    "Stationarity can be a bit tricky when dealing with Bayesian time series models. One choice is to enforce constraints on parameters. Or, you could not. This is fine if you just want to look at the distribution of the parameters. However, if you want to generate the posterior predictive, then you might have a lot of forecasts that explode.\n",
    "\n",
    "The Stan documentation provides a few examples where they put constraints on the parameters of time series models to ensure stationarity. This is possible for the relatively simple models they use, but it can be pretty much impossible in more complicated time series models. If you really wanted to enforce stationarity, you could use a Metropolis-Hastings algorithm and throw out any coefficients that are improper. However, this requires a lot of eigenvalues to be calculated, which will slow things down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining Fixed Effects: Random Effects Modeling of TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, I think you have to:\n",
    "\n",
    "- identify the missing mechanism of you data (MCAR, MAR, MNAR);\n",
    "\n",
    "(MCAR=missing completely at random; \n",
    "MAR=missing at random; \n",
    "MNAR (or NMAR)=missing not at random)\n",
    "\n",
    "\n",
    "For regression analysis. I find A. Sande, “A Sample Size Formula for Multiple Regression Studies,” Public Opinion Quarterly, Vol. 50, Spring 1986 very operational.\n",
    "\n",
    "Clive Granger: \"Empirical Modeling in Economics\" (Cambridge Press, 1999) addressed panel samples. He wrote:, \"most important macroeconomics series are rather short\", and he would do a \"post-sample\" evaluation for time-series, a \"cross-validation technique\" for cross-section data, and an mixture of both for panel data. (Ibid., pp. 65-66)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the solution for dealing with a small sample size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANDERSON-DARLING TEST\n",
    "\n",
    "According to the Anderson-Darling, the minimum sample size is n >5 or at least 6 elements. The test is used to determine the characteristic of the data distribution. In case where the population mean and variance is unknown, the critical value is 0.787 for 0.95 confidence interval. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
